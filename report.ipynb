{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "report_DDTECC.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "piigOf1ab143",
        "DJqkcRcSEbJ1",
        "usUCX03jF8Lz",
        "k4AdeLgWGCMy",
        "PotIlUVYGGZ9",
        "9U_kebyeGQaG",
        "InGkkIoKWus7",
        "HDk_MjSKGIsn",
        "46-2A863YGLG",
        "7DKO81DpI7EH",
        "0GnZ3-q8Zdzm",
        "iu3IXd5Op9DO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfnAX-aFAINo"
      },
      "source": [
        "# Experimental reports"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiments performed on 15 data sets:\n",
        "\n",
        "\n",
        "* Yeast                    \n",
        "* CAL500                   \n",
        "* VirusGO                  \n",
        "* Enron                    \n",
        "* Emotions                 \n",
        "* Genbase                  \n",
        "* Image                    \n",
        "* 3sources_bbc1000         \n",
        "* 3sources_guardian1000    \n",
        "* 3sources_inter3000       \n",
        "* Water-quality            \n",
        "* Medical                  \n",
        "* GnegativeGO              \n",
        "* GpositiveGO              \n",
        "* Scene                    \n",
        "\n",
        "Methodology \n",
        "\n",
        "The dataset is divided into 10 folds, in each iteration of cross-validation one of these folds is selected as the test set and the remaining folds are divided into validation and training sets in the ratio of 30% and 70%, respectively. Each DTECCd model with Phic in [0.0, 0.25, 0.5, 0.75, 1] is then trained on the training set and validated on the validation set. The results for each model are then compared according to a pre-selected metric [accuracy, fmeasure, subset accuracy, hamming loss] and the best model is selected and applied to the test set. After 10 rounds we will have the results for all folds in the original data set for the selected metric."
      ],
      "metadata": {
        "id": "JX5EcXLvu20n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_ICG7zyDWPJ"
      },
      "source": [
        "## Importing data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQl60AsaRpK8",
        "outputId": "e9eafd71-4a53-42e8-a367-3c79e318abcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9GxdLY0zPBM"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "datasets = [\"Genbase\", \"GnegativeGO\",\"Yeast\",\"Medical\",\"3sources_inter3000\",\"3sources_guardian1000\",\"Scene\",\"3sources_bbc1000\",\"VirusGO\",\"Emotions\",\"GpositiveGO\",\"Enron\",\"Image\", \"Water-quality\",\"CAL500\"]\n",
        "\n",
        "def pretty_arffname(arfffilename):\n",
        "  size = len(arfffilename)\n",
        "  slash_position = arfffilename.find('/', int(size/2))\n",
        "  return arfffilename[slash_position+1:size-5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## F-Measure"
      ],
      "metadata": {
        "id": "vyfJ3RUQCYmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparation"
      ],
      "metadata": {
        "id": "KitT1YTgYoYG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Clhc0m47zYnp"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Mestrado/DTECCMASK/phi search/FME/resultsFMEE.csv').fillna(0)\n",
        "\n",
        "df.arffFilename = df.arffFilename.apply(pretty_arffname)\n",
        "df = df[ df.arffFilename.isin(datasets) ]\n",
        "\n",
        "df.Learner = df.Learner.map({'EnsembleOfClassifierChainsStackSTACK': 'STACKECC', 'EnsembleOfClassifierChainsStack': 'STACKECC', 'EnsembleOfClassifierChainsDT': 'DTECC','EnsembleOfClassifierChainsMV': 'MVECC', 'EnsembleOfClassifierChainsME': 'MEECC'})\n",
        "df.drop(columns=['AverageMAE', 'AveragePrecision', 'AverageRMSE', 'Coverage', 'ErrorSetSize', 'LogLoss', 'MeanAveragePrecision', 'MeanSquaredError', 'MicroAUC', 'OneError', 'RankingLoss', 'RootMeanSquaredError'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF92dysKBZ53"
      },
      "source": [
        "df['ACC_Rank'] = df.groupby(['arffFilename'])['ExampleBasedAccuracy'].rank(ascending=False)\n",
        "df['PRE_Rank'] = df.groupby(['arffFilename'])['ExampleBasedPrecision'].rank(ascending=False)\n",
        "df['REC_Rank'] = df.groupby(['arffFilename'])['ExampleBasedRecall'].rank(ascending=False)\n",
        "df['SAC_Rank'] = df.groupby(['arffFilename'])['SubsetAccuracy'].rank(ascending=False)\n",
        "df['FME_Rank'] = df.groupby(['arffFilename'])['ExampleBasedFMeasure'].rank(ascending=False)\n",
        "df['HML_Rank'] = df.groupby(['arffFilename'])['HammingLoss'].rank(ascending=True)\n",
        "\n",
        "df_fme = df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9f6SZH3D1LZ"
      },
      "source": [
        "def create_metric_table(metric = 'ExampleBasedAccuracy', rank = 'ACC_Rank'):\n",
        "  df_mv = df[df.Learner == 'MVECC'][['arffFilename',\tmetric, rank]].set_index('arffFilename')\n",
        "  df_mv.columns = ['MV', 'RankMV']\n",
        "  df_mv[\"MVECC\"] = df_mv[\"MV\"].apply(\"{:.4f}\".format) + '(' + df_mv[\"RankMV\"].astype(str) + ')'\n",
        "\n",
        "  df_me = df[df.Learner == 'MEECC'][['arffFilename',\tmetric, rank]].set_index('arffFilename')\n",
        "  df_me.columns = ['ME', 'RankME']\n",
        "  df_me[\"MEECC\"] = df_me[\"ME\"].apply(\"{:.4f}\".format) + '(' + df_me[\"RankME\"].astype(str) + ')'\n",
        "  \n",
        "  df_st = df[df.Learner == 'STACKECC'][['arffFilename',\tmetric, rank]].set_index('arffFilename')\n",
        "  df_st.columns = ['ST', 'RankSTACK']\n",
        "  df_st[\"STACKECC\"] = df_st[\"ST\"].apply(\"{:.4f}\".format) + '(' + df_st[\"RankSTACK\"].astype(str) + ')'\n",
        "  \n",
        "  df_mk = df[df.Learner == 'DTECC'][['arffFilename',\tmetric, rank]].set_index('arffFilename')\n",
        "  df_mk.columns = ['MK', 'RankMASK']\n",
        "  df_mk[\"DTECCd\"] = df_mk[\"MK\"].apply(\"{:.4f}\".format) + '(' + df_mk[\"RankMASK\"].astype(str) + ')'\n",
        "\n",
        "  return df_mv.join(df_me).join(df_st).join(df_mk)[['DTECCd', 'MEECC', 'MVECC', 'STACKECC']].sort_values(by=['arffFilename'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "hhbqXc3bY3eD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average ranking for F-Measure"
      ],
      "metadata": {
        "id": "x8bjTV64ZRz9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBGMacUoCAv3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3892b751-19d0-456e-bbe4-9f84e27b71fa"
      },
      "source": [
        "df_mean_rank = df.groupby(['Learner'])[['FME_Rank']].mean()\n",
        "df_mean_rank.style.highlight_min(color='yellow')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7faacf5cba10>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_2260e_row0_col0 {\n",
              "  background-color: yellow;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_2260e_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >FME_Rank</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"index_name level0\" >Learner</th>\n",
              "      <th class=\"blank col0\" >&nbsp;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_2260e_level0_row0\" class=\"row_heading level0 row0\" >DTECC</th>\n",
              "      <td id=\"T_2260e_row0_col0\" class=\"data row0 col0\" >1.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2260e_level0_row1\" class=\"row_heading level0 row1\" >MEECC</th>\n",
              "      <td id=\"T_2260e_row1_col0\" class=\"data row1 col0\" >2.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2260e_level0_row2\" class=\"row_heading level0 row2\" >MVECC</th>\n",
              "      <td id=\"T_2260e_row2_col0\" class=\"data row2 col0\" >2.266667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2260e_level0_row3\" class=\"row_heading level0 row3\" >STACKECC</th>\n",
              "      <td id=\"T_2260e_row3_col0\" class=\"data row3 col0\" >3.200000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subset-accuracy"
      ],
      "metadata": {
        "id": "8-0bpW8jCet8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparation"
      ],
      "metadata": {
        "id": "d_37yNS7ZkLh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RhQ_Myn2QMZ"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Mestrado/DTECCMASK/phi search/SAC/resultsSACE.csv').fillna(0)\n",
        "\n",
        "df.arffFilename = df.arffFilename.apply(pretty_arffname)\n",
        "df = df[ df.arffFilename.isin(datasets) ]\n",
        "\n",
        "df.Learner = df.Learner.map({'EnsembleOfClassifierChainsStackSTACK': 'STACKECC', 'EnsembleOfClassifierChainsStack': 'STACKECC', 'EnsembleOfClassifierChainsDT': 'DTECC','EnsembleOfClassifierChainsMV': 'MVECC', 'EnsembleOfClassifierChainsME': 'MEECC'})\n",
        "df.drop(columns=['AverageMAE', 'AveragePrecision', 'AverageRMSE', 'Coverage', 'ErrorSetSize', 'LogLoss', 'MeanAveragePrecision', 'MeanSquaredError', 'MicroAUC', 'OneError', 'RankingLoss', 'RootMeanSquaredError'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5xQ1Uo93P6T"
      },
      "source": [
        "df['ACC_Rank'] = df.groupby(['arffFilename'])['ExampleBasedAccuracy'].rank(ascending=False)\n",
        "df['PRE_Rank'] = df.groupby(['arffFilename'])['ExampleBasedPrecision'].rank(ascending=False)\n",
        "df['REC_Rank'] = df.groupby(['arffFilename'])['ExampleBasedRecall'].rank(ascending=False)\n",
        "df['SAC_Rank'] = df.groupby(['arffFilename'])['SubsetAccuracy'].rank(ascending=False)\n",
        "df['FME_Rank'] = df.groupby(['arffFilename'])['ExampleBasedFMeasure'].rank(ascending=False)\n",
        "df['HML_Rank'] = df.groupby(['arffFilename'])['HammingLoss'].rank(ascending=True)\n",
        "\n",
        "df_sac = df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "GeQvX0VdZ7ar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average ranking for Subset Accuracy"
      ],
      "metadata": {
        "id": "0CZjrnt4awM-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tyguxs93fp-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ae1673f6-5a68-4683-898d-52ea0fa942fd"
      },
      "source": [
        "df_mean_rank = df.groupby(['Learner'])[['SAC_Rank']].mean()\n",
        "df_mean_rank.style.highlight_min(color='yellow')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7faace7aba10>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_ec9f0_row0_col0 {\n",
              "  background-color: yellow;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_ec9f0_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >SAC_Rank</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"index_name level0\" >Learner</th>\n",
              "      <th class=\"blank col0\" >&nbsp;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_ec9f0_level0_row0\" class=\"row_heading level0 row0\" >DTECC</th>\n",
              "      <td id=\"T_ec9f0_row0_col0\" class=\"data row0 col0\" >2.033333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ec9f0_level0_row1\" class=\"row_heading level0 row1\" >MEECC</th>\n",
              "      <td id=\"T_ec9f0_row1_col0\" class=\"data row1 col0\" >2.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ec9f0_level0_row2\" class=\"row_heading level0 row2\" >MVECC</th>\n",
              "      <td id=\"T_ec9f0_row2_col0\" class=\"data row2 col0\" >2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ec9f0_level0_row3\" class=\"row_heading level0 row3\" >STACKECC</th>\n",
              "      <td id=\"T_ec9f0_row3_col0\" class=\"data row3 col0\" >3.266667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy"
      ],
      "metadata": {
        "id": "r6ntNigRDm-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparation"
      ],
      "metadata": {
        "id": "sH_wUQz0aMhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Mestrado/DTECCMASK/phi search/ACC/resultsACCE.csv').fillna(0)\n",
        "df.arffFilename = df.arffFilename.apply(pretty_arffname)\n",
        "df = df[ df.arffFilename.isin(datasets) ]\n",
        "df.Learner = df.Learner.map({'EnsembleOfClassifierChainsStack': 'STACKECC', 'EnsembleOfClassifierChainsDT': 'DTECC','EnsembleOfClassifierChainsMV': 'MVECC', 'EnsembleOfClassifierChainsME': 'MEECC'})\n",
        "df.drop(columns=['AverageMAE', 'AveragePrecision', 'AverageRMSE', 'Coverage', 'ErrorSetSize', 'LogLoss', 'MeanAveragePrecision', 'MeanSquaredError', 'MicroAUC', 'OneError', 'RankingLoss', 'RootMeanSquaredError'], inplace=True)"
      ],
      "metadata": {
        "id": "8H2q5_JGDowv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['ACC_Rank'] = df.groupby(['arffFilename'])['ExampleBasedAccuracy'].rank(ascending=False)\n",
        "df['PRE_Rank'] = df.groupby(['arffFilename'])['ExampleBasedPrecision'].rank(ascending=False)\n",
        "df['REC_Rank'] = df.groupby(['arffFilename'])['ExampleBasedRecall'].rank(ascending=False)\n",
        "df['SAC_Rank'] = df.groupby(['arffFilename'])['SubsetAccuracy'].rank(ascending=False)\n",
        "df['FME_Rank'] = df.groupby(['arffFilename'])['ExampleBasedFMeasure'].rank(ascending=False)\n",
        "df['HML_Rank'] = df.groupby(['arffFilename'])['HammingLoss'].rank(ascending=True)\n",
        "\n",
        "df_acc = df"
      ],
      "metadata": {
        "id": "Wb79teEoD-aL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "QYUQ2aUjaN2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average ranking for Accuracy"
      ],
      "metadata": {
        "id": "7zJhJKNwaxqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_mean_rank = df.groupby(['Learner'])[['ACC_Rank']].mean()\n",
        "df_mean_rank.style.highlight_min(color='yellow')"
      ],
      "metadata": {
        "id": "usYDagWYEHon",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "374d049d-32a2-4e13-c574-3f6349733933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7faace7b1a50>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_1ddb6_row0_col0 {\n",
              "  background-color: yellow;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_1ddb6_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >ACC_Rank</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"index_name level0\" >Learner</th>\n",
              "      <th class=\"blank col0\" >&nbsp;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_1ddb6_level0_row0\" class=\"row_heading level0 row0\" >DTECC</th>\n",
              "      <td id=\"T_1ddb6_row0_col0\" class=\"data row0 col0\" >1.766667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1ddb6_level0_row1\" class=\"row_heading level0 row1\" >MEECC</th>\n",
              "      <td id=\"T_1ddb6_row1_col0\" class=\"data row1 col0\" >2.733333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1ddb6_level0_row2\" class=\"row_heading level0 row2\" >MVECC</th>\n",
              "      <td id=\"T_1ddb6_row2_col0\" class=\"data row2 col0\" >2.433333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1ddb6_level0_row3\" class=\"row_heading level0 row3\" >STACKECC</th>\n",
              "      <td id=\"T_1ddb6_row3_col0\" class=\"data row3 col0\" >3.066667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hamming Loss\n"
      ],
      "metadata": {
        "id": "MRVVMN331GgX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparation"
      ],
      "metadata": {
        "id": "9NYrdpXQaRqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Mestrado/DTECCMASK/phi search/HML/resultsHMLE.csv').fillna(0)\n",
        "\n",
        "def pretty_arffname(arfffilename):\n",
        "  size = len(arfffilename)\n",
        "  slash_position = arfffilename.find('/', int(size/2))\n",
        "  return arfffilename[slash_position+1:size-5]\n",
        "\n",
        "\n",
        "df.arffFilename = df.arffFilename.apply(pretty_arffname)\n",
        "\n",
        "#df = df[ (df.arffFilename == \"Water-quality\") | (df.arffFilename == \"Medical\") | (df.arffFilename == \"GnegativeGO\") | (df.arffFilename == \"Genbase\") | (df.arffFilename == \"Enron\") | (df.arffFilename == \"Emotions\") | (df.arffFilename == \"CAL500\") | (df.arffFilename == \"3sources_inter3000\") | (df.arffFilename == \"3sources_guardian1000\") | (df.arffFilename == \"VirusGO\") | (df.arffFilename == \"GpositiveGO\") ]#| (df.arffFilename == \"Yeast\") | (df.arffFilename == \"Image\") | (df.arffFilename == \"3sources_bbc1000\") | (df.arffFilename == \"Scene\")\n",
        "'''\n",
        "Yeast                    3\n",
        "Image                    3\n",
        "3sources_bbc1000         3\n",
        "Scene                    3\n",
        "'''\n",
        "df = df[ df.arffFilename.isin(datasets) ]\n",
        "\n",
        "\n",
        "df.Learner = df.Learner.map({'EnsembleOfClassifierChainsStack': 'STACKECC', 'EnsembleOfClassifierChainsDT': 'DTECC','EnsembleOfClassifierChainsMV': 'MVECC', 'EnsembleOfClassifierChainsME': 'MEECC'})\n",
        "df = df[ (df.Learner != \"MLS\") ]\n",
        "df.drop(columns=['AverageMAE', 'AveragePrecision', 'AverageRMSE', 'Coverage', 'ErrorSetSize', 'LogLoss', 'MeanAveragePrecision', 'MeanSquaredError', 'MicroAUC', 'OneError', 'RankingLoss', 'RootMeanSquaredError'], inplace=True)"
      ],
      "metadata": {
        "id": "bdyLU5Ch1Ple"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['ACC_Rank'] = df.groupby(['arffFilename'])['ExampleBasedAccuracy'].rank(ascending=False)\n",
        "df['PRE_Rank'] = df.groupby(['arffFilename'])['ExampleBasedPrecision'].rank(ascending=False)\n",
        "df['REC_Rank'] = df.groupby(['arffFilename'])['ExampleBasedRecall'].rank(ascending=False)\n",
        "df['SAC_Rank'] = df.groupby(['arffFilename'])['SubsetAccuracy'].rank(ascending=False)\n",
        "df['FME_Rank'] = df.groupby(['arffFilename'])['ExampleBasedFMeasure'].rank(ascending=False)\n",
        "df['HML_Rank'] = df.groupby(['arffFilename'])['HammingLoss'].rank(ascending=True)\n",
        "\n",
        "df_hml = df"
      ],
      "metadata": {
        "id": "seVynFZ_caMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "rRp8kYIDaWzt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average ranking for Hamming Loss"
      ],
      "metadata": {
        "id": "XcPB_1oPaz9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_mean_rank = df.groupby(['Learner'])[['HML_Rank']].mean()\n",
        "df_mean_rank.style.highlight_min(color='yellow')"
      ],
      "metadata": {
        "id": "5Ei6CzKg1wVV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ed93dc74-81cf-4027-c14f-842df22eea9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7faace7afd10>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_3fdd2_row1_col0 {\n",
              "  background-color: yellow;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_3fdd2_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >HML_Rank</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"index_name level0\" >Learner</th>\n",
              "      <th class=\"blank col0\" >&nbsp;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_3fdd2_level0_row0\" class=\"row_heading level0 row0\" >DTECC</th>\n",
              "      <td id=\"T_3fdd2_row0_col0\" class=\"data row0 col0\" >2.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3fdd2_level0_row1\" class=\"row_heading level0 row1\" >MEECC</th>\n",
              "      <td id=\"T_3fdd2_row1_col0\" class=\"data row1 col0\" >1.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3fdd2_level0_row2\" class=\"row_heading level0 row2\" >MVECC</th>\n",
              "      <td id=\"T_3fdd2_row2_col0\" class=\"data row2 col0\" >2.533333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3fdd2_level0_row3\" class=\"row_heading level0 row3\" >STACKECC</th>\n",
              "      <td id=\"T_3fdd2_row3_col0\" class=\"data row3 col0\" >3.366667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJbujYPFrqwZ"
      },
      "source": [
        "# Friedman-Nemenyi\n",
        "\n",
        "https://orange3.readthedocs.io/projects/orange-data-mining-library/en/latest/reference/evaluation.cd.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install orange3"
      ],
      "metadata": {
        "id": "JkEasBCHevXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compare_table(df, metric):\n",
        "  df_mv = df[df.Learner == 'MVECC'][['arffFilename',\tmetric]].set_index('arffFilename')\n",
        "  df_mv.columns = ['MVECC']\n",
        "\n",
        "  df_me = df[df.Learner == 'MEECC'][['arffFilename',\tmetric]].set_index('arffFilename')\n",
        "  df_me.columns = ['MEECC']\n",
        "  \n",
        "  df_dtf = df[df.Learner == 'DTECC'][['arffFilename',\tmetric]].set_index('arffFilename')\n",
        "  df_dtf.columns = ['DTECC']\n",
        "\n",
        "  df_st = df[df.Learner == 'STACKECC'][['arffFilename',\tmetric]].set_index('arffFilename')\n",
        "  df_st.columns = ['STACKECC']\n",
        "\n",
        "  return df_mv.join(df_me).join(df_dtf).join(df_st)"
      ],
      "metadata": {
        "id": "1sI1IpEDfYOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVP3hLJzq2pi"
      },
      "source": [
        "from Orange.evaluation import compute_CD, graph_ranks\n",
        "from scipy.stats import wilcoxon, friedmanchisquare, rankdata\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def friedman_nemeyi_test(df, metric, ascending=False):\n",
        "  df_metric = compare_table(df, metric)\n",
        "  # First, we extract the algorithms names.\n",
        "  algorithms_names = df_metric.columns\n",
        "  # Then, we extract the performances as a numpy.ndarray.\n",
        "  performances_array = df_metric[algorithms_names].values\n",
        "  # Finally, we apply the Friedman test.\n",
        "  print(friedmanchisquare(*performances_array))\n",
        "\n",
        "  # Calculating the ranks of the algorithms for each dataset. The value of p is multipled by -1\n",
        "  # because the rankdata method ranks from the smallest to the greatest performance values.\n",
        "  # Since we are considering AUC as our performance measure, we want larger values to be best ranked.\n",
        "  multiplier = 1 if ascending else -1\n",
        "  ranks = np.array([rankdata(multiplier*p) for p in performances_array])\n",
        "  # Calculating the average ranks.\n",
        "  average_ranks = np.mean(ranks, axis=0)\n",
        "  print('\\n'.join('{} average rank: {}'.format(a, r) for a, r in zip(algorithms_names, average_ranks)))\n",
        "\n",
        "  # This method computes the critical difference for Nemenyi test with alpha=0.1.\n",
        "  # For some reason, this method only accepts alpha='0.05' or alpha='0.1'.\n",
        "  cd = compute_CD(average_ranks,\n",
        "    n=len(df_metric),\n",
        "    alpha='0.1',\n",
        "    test='nemenyi')\n",
        "  # This method generates the plot.\n",
        "  graph_ranks(average_ranks,\n",
        "    names=algorithms_names,\n",
        "    cd=cd,\n",
        "    width=4,\n",
        "    textspace=1.5,\n",
        "    reverse=True)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "friedman_nemeyi_test(df_fme, 'ExampleBasedFMeasure')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "8Q8QzKyYg0TK",
        "outputId": "69e7d45c-f390-4079-a5a8-16391f0bf63a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FriedmanchisquareResult(statistic=51.875, pvalue=2.9523722212766094e-06)\n",
            "MVECC average rank: 2.2666666666666666\n",
            "MEECC average rank: 2.6\n",
            "DTECC average rank: 1.9333333333333333\n",
            "STACKECC average rank: 3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x118.8 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "friedman_nemeyi_test(df_acc, 'ExampleBasedAccuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "Y3IQv94Ig9mk",
        "outputId": "dcef7e1d-0c6f-463b-baf5-b85351fe89c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FriedmanchisquareResult(statistic=50.60000000000002, pvalue=4.843191325641056e-06)\n",
            "MVECC average rank: 2.433333333333333\n",
            "MEECC average rank: 2.7333333333333334\n",
            "DTECC average rank: 1.7666666666666666\n",
            "STACKECC average rank: 3.066666666666667\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x118.8 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "friedman_nemeyi_test(df_sac, 'SubsetAccuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "aIZw-V-dhC8k",
        "outputId": "403ebc06-21d4-44f9-b822-76d4a86e474f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FriedmanchisquareResult(statistic=47.688869021010284, pvalue=1.4798929449216794e-05)\n",
            "MVECC average rank: 2.5\n",
            "MEECC average rank: 2.2\n",
            "DTECC average rank: 2.033333333333333\n",
            "STACKECC average rank: 3.2666666666666666\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x118.8 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "friedman_nemeyi_test(df_hml, 'HammingLoss', True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "WGxLbBA5hJMU",
        "outputId": "62c69f8d-941c-4c6a-bd1d-ab4a28fa5ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FriedmanchisquareResult(statistic=37.400000000000006, pvalue=0.0006415365238120967)\n",
            "MVECC average rank: 2.533333333333333\n",
            "MEECC average rank: 1.9333333333333333\n",
            "DTECC average rank: 2.1666666666666665\n",
            "STACKECC average rank: 3.3666666666666667\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x118.8 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}